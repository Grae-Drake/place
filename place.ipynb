{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# r/place Explorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Place](https://www.reddit.com/r/place/) is cool. But a [static image](https://i.redd.it/o4oku48qk9py.png) doesn't tell the story of [battles won](https://gfycat.com/InfamousShyEeve) or [characters evolving](http://i.imgur.com/KVXH8G4.png) over time, and it's tough to find and point out all the [amazing details](https://i.redd.it/glxdg7d23cpy.png), particularly ephemeral ones that were [overwritten](https://i.redd.it/qtvc4dai7soy.png).\n",
    "\n",
    "That's why we need an interactive playable, rewindable, annotatable _place explorer_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An interactive guide\n",
    "\n",
    "A decent [corpus of data exists](http://spacescience.tech/place/img/) comprised of individual frames. Our job is to convert that ~5gb of images into a manageable amount of data that can quickly be transferred to the client, then use that data to create an interactive canvas that can be played forward or backwards in time.\n",
    "\n",
    "Once we have interactive dynamic display, we can add annotations. Annotations consist of a title (\"Skeletor smokes a blunt\"), a time window (start time & stop time) and a location window (two points defining a rectangle of interest).\n",
    "\n",
    "Users can add new annotations, which are stored in a database. They can also upvote existing annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring and processing the data\n",
    "\n",
    "Before we can do any of this we need to acquire the raw data and process it into a managable form.\n",
    "\n",
    "The process here is to grab the initial image, then the next image and diff the two, storing any changed pixels in a list. This list describes how to efficiently get from one image to the next. All 23k images can be stored this way in a reasonable amount of space, and an HTML canvas should be able to handle updates like this just fine.\n",
    "\n",
    "Below is some noodling on getting the data. So far we're grabbing and processing individual images and individual diffs. To do includes automatically downloading and processing _all_ of the images and writing the aggregate diffs to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function scipy.misc.pilutil.imread>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.misc.imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1 = scipy.misc.imread('1.png').reshape(1000000, 3).tolist()\n",
    "img2 = scipy.misc.imread('2.png').reshape(1000000, 3).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2993, [34, 34, 34]),\n",
       " (5073, [34, 34, 34]),\n",
       " (19442, [34, 34, 34]),\n",
       " (20981, [255, 255, 255]),\n",
       " (21900, [255, 167, 209]),\n",
       " (34103, [229, 0, 0]),\n",
       " (34108, [229, 0, 0]),\n",
       " (34237, [34, 34, 34]),\n",
       " (35003, [229, 0, 0]),\n",
       " (35168, [34, 34, 34])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped = zip(img1, img2)\n",
    "type(zipped)\n",
    "delta = [(i, item[1]) for i, item in enumerate(zipped) if item[0] != item[1]]\n",
    "delta[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i1 = requests.get(\"http://spacescience.tech/place/img/1491209117.png\")\n",
    "i2 = requests.get(\"http://spacescience.tech/place/img/1491209126.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgg1 = Image.open(BytesIO(i1.content))\n",
    "imgg2 = Image.open(BytesIO(i2.content))\n",
    "\n",
    "a = np.asarray(imgg1).reshape(1000000).tolist()\n",
    "b = np.asarray(imgg2).reshape(1000000).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35251, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zapped = zip(a, b)\n",
    "delt = [(i, item[1]) for i, item in enumerate(zapped) if item[0] != item[1]]\n",
    "delt[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get image file list.\n",
    "# Get first image. Baseline.\n",
    "# Get second image. Diff, write to file. Repeat."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
